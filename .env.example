# LM Watermark Lab Environment Configuration

# Application Settings
APP_NAME="LM Watermark Lab"
APP_VERSION="1.0.0"
DEBUG=false
LOG_LEVEL=INFO

# API Configuration
API_HOST=0.0.0.0
API_PORT=8080
API_WORKERS=4
API_RELOAD=false

# Security
SECRET_KEY=your-secret-key-here-change-in-production
ACCESS_TOKEN_EXPIRE_MINUTES=30
ALGORITHM=HS256

# Database Configuration (if using database)
DATABASE_URL=sqlite:///./watermark_lab.db
# DATABASE_URL=postgresql://user:password@localhost:5432/watermark_lab

# Redis Configuration (for caching and task queue)
REDIS_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# Model Storage
MODEL_CACHE_PATH=./data/models
MODEL_CACHE_SIZE_GB=50
HUGGINGFACE_CACHE_DIR=./data/hf_cache

# Data Paths
DATA_ROOT=./data
EXPERIMENTS_PATH=./data/experiments
DATASETS_PATH=./data/datasets
CONFIGS_PATH=./configs

# Logging
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s
LOG_FILE=./logs/watermark_lab.log
LOG_MAX_SIZE_MB=100
LOG_BACKUP_COUNT=5

# Monitoring & Observability
ENABLE_METRICS=true
METRICS_PORT=9090
ENABLE_TRACING=false
JAEGER_ENDPOINT=http://localhost:14268/api/traces

# External Services
OPENAI_API_KEY=your-openai-api-key
ANTHROPIC_API_KEY=your-anthropic-api-key
HUGGINGFACE_TOKEN=your-huggingface-token

# Weights & Biases (for experiment tracking)
WANDB_API_KEY=your-wandb-api-key
WANDB_PROJECT=lm-watermark-lab
WANDB_ENTITY=your-wandb-entity

# Performance Settings
MAX_CONCURRENT_REQUESTS=100
REQUEST_TIMEOUT_SECONDS=300
BATCH_SIZE_LIMIT=32
MAX_TEXT_LENGTH=10000

# CUDA/GPU Configuration
CUDA_VISIBLE_DEVICES=0
TORCH_NUM_THREADS=4
OMP_NUM_THREADS=4

# Development Settings
PYTEST_TIMEOUT=300
COVERAGE_THRESHOLD=80
ENABLE_PROFILING=false

# Production Settings
ENABLE_CORS=true
CORS_ORIGINS=["http://localhost:3000", "http://localhost:8080"]
ENABLE_RATE_LIMITING=true
RATE_LIMIT_PER_MINUTE=60

# Docker Settings
DOCKER_REGISTRY=your-registry.com
DOCKER_TAG=latest
DOCKER_BUILD_ARGS=""