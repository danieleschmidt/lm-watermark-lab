"""Test Generation 3 performance optimization features."""

import sys
import os
import time
import threading
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

def test_performance_cache():
    """Test performance caching system."""
    try:
        from watermark_lab.optimization.performance_cache import (
            PerformanceCache, CacheStrategy, CacheManager, cached
        )
        
        print("‚úì Performance cache imported successfully")
        
        # Test basic cache operations
        cache = PerformanceCache(max_size=100, strategy=CacheStrategy.LRU)
        
        # Test put/get
        cache.put("test_key", "test_value")
        result = cache.get("test_key")
        assert result == "test_value"
        print("‚úì Basic cache operations work")
        
        # Test cache statistics
        stats = cache.get_stats()
        print(f"‚úì Cache stats: {stats['size']} items, {stats['hit_rate']:.2f} hit rate")
        
        # Test cache decorator
        @cached(cache_name="test_cache", ttl=10.0)
        def expensive_function(x):
            time.sleep(0.01)  # Simulate work
            return x * 2
        
        # First call should be slow
        start = time.time()
        result1 = expensive_function(5)
        time1 = time.time() - start
        
        # Second call should be fast (cached)
        start = time.time()
        result2 = expensive_function(5)
        time2 = time.time() - start
        
        assert result1 == result2 == 10
        assert time2 < time1  # Should be faster
        print(f"‚úì Cache decorator works: {time1:.3f}s -> {time2:.3f}s")
        
        # Test cache manager
        manager = CacheManager()
        test_cache = manager.get_cache("test", max_size=50)
        all_stats = manager.get_all_stats()
        print(f"‚úì Cache manager: {len(all_stats)} caches")
        
        return True
        
    except Exception as e:
        print(f"‚úó Performance cache test error: {e}")
        return False

def test_concurrent_processing():
    """Test concurrent processing system."""
    try:
        from watermark_lab.optimization.concurrent_processing import (
            ConcurrentExecutor, ResourcePool, Priority, PoolType
        )
        
        print("‚úì Concurrent processing imported successfully")
        
        # Test resource pool
        def create_resource():
            return {"id": time.time(), "data": "test"}
        
        def cleanup_resource(resource):
            pass  # No cleanup needed for test
        
        pool = ResourcePool(
            create_func=create_resource,
            cleanup_func=cleanup_resource,
            max_size=5,
            min_size=1
        )
        
        # Test resource management
        with pool.get_resource() as resource:
            assert "id" in resource
            print("‚úì Resource pool management works")
        
        pool_stats = pool.get_stats()
        print(f"‚úì Resource pool stats: {pool_stats['pool_size']} available")
        
        # Test concurrent executor
        executor = ConcurrentExecutor(
            pool_type=PoolType.THREAD,
            max_workers=2,
            queue_size=100
        )
        
        def test_task(x, y):
            time.sleep(0.01)  # Simulate work
            return x + y
        
        # Submit tasks
        task_ids = []
        for i in range(5):
            task_id = executor.submit(
                test_task, 
                i, i*2, 
                priority=Priority.NORMAL
            )
            task_ids.append(task_id)
        
        # Wait for results
        results = []
        for task_id in task_ids:
            result = executor.get_result(task_id, timeout=5.0)
            results.append(result)
        
        # Verify results
        assert all(r.success for r in results)
        print(f"‚úì Concurrent execution: {len(results)} tasks completed")
        
        executor_stats = executor.get_stats()
        print(f"‚úì Executor stats: {executor_stats['success_rate']:.2f} success rate")
        
        executor.shutdown()
        return True
        
    except Exception as e:
        print(f"‚úó Concurrent processing test error: {e}")
        return False

def test_auto_scaling():
    """Test auto-scaling system."""
    try:
        from watermark_lab.optimization.auto_scaling import (
            LoadBalancer, AutoScaler, LoadMetric, ScalingDirection
        )
        
        print("‚úì Auto-scaling imported successfully")
        
        # Test load balancer
        lb = LoadBalancer()
        
        # Register test workers
        lb.register_worker("worker_1", "http://localhost:8001", capacity=100)
        lb.register_worker("worker_2", "http://localhost:8002", capacity=100)
        
        # Test worker selection
        worker = lb.get_best_worker(strategy="least_loaded")
        assert worker in ["worker_1", "worker_2"]
        print("‚úì Load balancer worker selection works")
        
        # Test request tracking
        lb.record_request_start(worker)
        time.sleep(0.01)
        lb.record_request_end(worker, success=True, response_time=0.1)
        
        lb_stats = lb.get_stats()
        print(f"‚úì Load balancer stats: {lb_stats['healthy_workers']} healthy workers")
        
        # Test auto-scaler
        scaler = AutoScaler(
            min_workers=1,
            max_workers=5,
            evaluation_window=1.0,  # Short window for testing
            cooldown_period=0.1     # Short cooldown for testing
        )
        
        # Simulate load
        for _ in range(10):
            scaler.record_load_sample(LoadMetric.CPU_USAGE, 0.9)  # High load
        
        scaler_stats = scaler.get_stats()
        print(f"‚úì Auto-scaler: {scaler_stats['current_workers']} workers")
        
        scaler.stop()
        return True
        
    except Exception as e:
        print(f"‚úó Auto-scaling test error: {e}")
        return False

def test_integration_performance():
    """Test integrated performance features."""
    try:
        from watermark_lab.optimization.performance_cache import get_cache_manager
        from watermark_lab.optimization.concurrent_processing import get_resource_manager
        
        print("‚úì Performance integration imported successfully")
        
        # Test global managers
        cache_manager = get_cache_manager()
        resource_manager = get_resource_manager()
        
        # Test cache manager
        test_cache = cache_manager.get_cache("integration_test")
        test_cache.put("test", "value")
        assert test_cache.get("test") == "value"
        print("‚úì Global cache manager works")
        
        # Test resource manager
        executor = resource_manager.get_executor("test_executor")
        
        def simple_task():
            return "completed"
        
        task_id = executor.submit(simple_task)
        result = executor.get_result(task_id, timeout=5.0)
        assert result.success
        assert result.result == "completed"
        print("‚úì Global resource manager works")
        
        # Test combined stats
        cache_stats = cache_manager.get_all_stats()
        resource_stats = resource_manager.get_all_stats()
        
        print(f"‚úì Integrated stats: {len(cache_stats)} caches, {len(resource_stats['executors'])} executors")
        
        return True
        
    except Exception as e:
        print(f"‚úó Integration performance test error: {e}")
        return False

def test_memory_efficiency():
    """Test memory efficiency features."""
    try:
        from watermark_lab.optimization.performance_cache import (
            PerformanceCache, CacheStrategy
        )
        
        print("‚úì Memory efficiency test starting")
        
        # Test memory-limited cache
        cache = PerformanceCache(
            max_size=1000,
            max_memory_mb=1.0,  # 1MB limit
            strategy=CacheStrategy.ADAPTIVE
        )
        
        # Fill cache with data
        large_data = "x" * 1024  # 1KB strings
        stored_count = 0
        
        for i in range(2000):  # Try to store 2MB of data
            cache.put(f"key_{i}", large_data)
            stored_count += 1
            
            stats = cache.get_stats()
            if stats['memory_mb'] >= 0.9:  # Near limit
                break
        
        final_stats = cache.get_stats()
        print(f"‚úì Memory efficiency: stored {stored_count} items, {final_stats['memory_mb']:.2f}MB used")
        
        # Verify memory limit was respected
        assert final_stats['memory_mb'] <= 1.1  # Allow small overage
        print("‚úì Memory limits enforced")
        
        return True
        
    except Exception as e:
        print(f"‚úó Memory efficiency test error: {e}")
        return False

if __name__ == "__main__":
    print("=== Generation 3 Performance Tests ===")
    
    tests = [
        test_performance_cache,
        test_concurrent_processing,
        test_auto_scaling,
        test_integration_performance,
        test_memory_efficiency
    ]
    
    passed = 0
    for test in tests:
        print(f"\n--- {test.__name__} ---")
        if test():
            passed += 1
    
    print(f"\n=== Results: {passed}/{len(tests)} tests passed ===")
    
    if passed == len(tests):
        print("üéâ Generation 3 performance optimization complete!")
        print("üöÄ System ready for high-scale production workloads!")
    elif passed >= len(tests) * 0.6:  # 60% pass rate
        print("‚ö° Generation 3 performance features mostly working!")
        print("üîß Some optimizations may need fine-tuning for your environment")
    else:
        print("‚ö†Ô∏è  Some performance tests failed")
        print("üí° Performance features implemented but may need dependencies")